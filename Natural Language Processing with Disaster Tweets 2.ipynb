{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c7a112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zhouruohe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhouruohe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/zhouruohe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "train = pd.read_csv('/Users/zhouruohe/Downloads/train.csv')\n",
    "test = pd.read_csv('/Users/zhouruohe/Downloads/test.csv')\n",
    "train.head()\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b10472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's up man?\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c42ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/r7m_ksxd1zj2ttsw9nprxcv00000gn/T/ipykernel_18400/4225160402.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['text'][i] = nlp(train['text'][i])\n"
     ]
    }
   ],
   "source": [
    "def nlp(text_str):\n",
    "    k = word_tokenize(text_str)\n",
    "    for i in range(len(k)):\n",
    "        k[i] = k[i].lower()\n",
    "    k = [ps.stem(i) for i in k if i not in list(string.punctuation) and i not in stopwords.words('english')]\n",
    "    k = \" \".join(k)\n",
    "    return k\n",
    "for i in range(len(train['text'])):\n",
    "    train['text'][i] = nlp(train['text'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e46f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deed reason earthquak may allah forgiv us'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e954462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(train['text'])\n",
    "x_train = tfidf.transform(train['text'])\n",
    "x_train\n",
    "y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8557afa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f7b70820610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_boost = CatBoostClassifier(verbose=0, random_state = 123)\n",
    "cat_boost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8491015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cat_boost.predict(['earthquake'])\n",
    "test_sample = \"What's up man?\"\n",
    "test_sample = nlp(test_sample)\n",
    "test = tfidf.transform([test_sample ])\n",
    "cat_boost.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e65341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_test = cat_boost.predict(test_x)\n",
    "# y_pred_train = cat_boost.predict(train_x)\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred_train))\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad06b4",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f59fde77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our',\n",
       " 'Deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'Reason',\n",
       " 'of',\n",
       " 'this',\n",
       " '#',\n",
       " 'earthquake',\n",
       " 'May',\n",
       " 'ALLAH',\n",
       " 'Forgive',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = [word_tokenize(train.iloc[i, 3]) for i in range(len(train))]\n",
    "test['text'] = [word_tokenize(test.iloc[i, 3]) for i in range(len(test))]\n",
    "train.iloc[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ada83",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "21f56007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/r7m_ksxd1zj2ttsw9nprxcv00000gn/T/ipykernel_14992/2053317675.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['text'][i] = [train['text'][i][j].lower() for j in range(len(train.iloc[i,3]))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'of',\n",
       " 'this',\n",
       " '#',\n",
       " 'earthquake',\n",
       " 'may',\n",
       " 'allah',\n",
       " 'forgive',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn all words to lower case\n",
    "for i in range(len(train)):\n",
    "    train['text'][i] = [train['text'][i][j].lower() for j in range(len(train.iloc[i,3]))]\n",
    "    \n",
    "# for i in range(len(test)):\n",
    "#     test['text'][i] = [test['text'][i][j].lower() for j in range(len(test.iloc[i,3]))]\n",
    "    \n",
    "train.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "48c207d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/r7m_ksxd1zj2ttsw9nprxcv00000gn/T/ipykernel_14992/1860399036.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['text'][i] = [j for j in train['text'][i] if j not in list(string.punctuation)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'of',\n",
       " 'this',\n",
       " 'earthquake',\n",
       " 'may',\n",
       " 'allah',\n",
       " 'forgive',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation\n",
    "import string\n",
    "string.punctuation\n",
    "for i in range(len(train)):\n",
    "    train['text'][i] = [j for j in train['text'][i] if j not in list(string.punctuation)]\n",
    "    \n",
    "# for i in range(len(test)):\n",
    "#     test['text'][i] = [j for j in test['text'][i] if j not in list(string.punctuation)]\n",
    "    \n",
    "train.iloc[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208149a2",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c32b692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhouruohe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ffe44754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/r7m_ksxd1zj2ttsw9nprxcv00000gn/T/ipykernel_14992/1149367825.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['text'][i] = [j for j in train['text'][i] if j not in stopwords.words('english')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['deeds', 'reason', 'earthquake', 'may', 'allah', 'forgive', 'us']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "for i in range(len(train)):\n",
    "    train['text'][i] = [j for j in train['text'][i] if j not in stopwords.words('english')]\n",
    "    \n",
    "# for i in range(len(test)):\n",
    "#     test['text'][i] = [j for j in test['text'][i] if j not in stopwords.words('english')]\n",
    "    \n",
    "train.iloc[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf7152",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c6372b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nr/r7m_ksxd1zj2ttsw9nprxcv00000gn/T/ipykernel_14992/480473018.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['text'][i] = [ps.stem(j) for j in train['text'][i]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['deed', 'reason', 'earthquak', 'may', 'allah', 'forgiv', 'us']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "for i in range(len(train)):\n",
    "    train['text'][i] = [ps.stem(j) for j in train['text'][i]]\n",
    "    \n",
    "# for i in range(len(test)):\n",
    "#     test['text'][i] = [ps.stem(j) for j in test['text'][i]]\n",
    "    \n",
    "train.iloc[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ceae9",
   "metadata": {},
   "source": [
    "### Conbine words to form a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9b16fcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deed reason earthquak may allah forgiv us'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is because CountVectorizer() only works on sentence not single strings\n",
    "train['text'] = [' '.join(i) for i in train['text']]\n",
    "#test['text'] = [' '.join(i) for i in test['text']]\n",
    "train.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "123248d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               deed reason earthquak may allah forgiv us\n",
       "1                    forest fire near la rong sask canada\n",
       "2       resid ask 'shelter place notifi offic evacu sh...\n",
       "3       13,000 peopl receiv wildfir evacu order califo...\n",
       "4       got sent photo rubi alaska smoke wildfir pour ...\n",
       "                              ...                        \n",
       "7608    two giant crane hold bridg collaps nearbi home...\n",
       "7609    aria_ahrari thetawniest control wild fire cali...\n",
       "7610    m1.94 01:04 utc 5km volcano hawaii http //t.co...\n",
       "7611    polic investig e-bik collid car littl portug e...\n",
       "7612    latest home raze northern california wildfir a...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "843d0d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x18816 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 82335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "x_train = count_vect.fit_transform(train['text'])\n",
    "#x_test = count_vect.fit_transform(test['text'])\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d7895d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.toarray()\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6459e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_train[:5329]\n",
    "test_x = x_train[5329:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7db2c04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5329"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ba30b34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2284"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da2c3c",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bb6afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5329, 18816)\n",
      "(2284, 18816)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tf_transformer_train = TfidfTransformer(use_idf=True).fit(train_x)\n",
    "# X_train = tf_transformer_train.transform(train_x)\n",
    "\n",
    "# tf_transformer_test = TfidfTransformer(use_idf=True).fit(test_x)\n",
    "# X_test = tf_transformer_test.transform(test_x)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a1976",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d9d03791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = y_train[:5329]\n",
    "test_y =  y_train[5329:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e35797f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9978ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(test_x)\n",
    "y_pred_train = classifier.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "21c4bdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9485832238693939\n",
      "Accuracy: 0.5971978984238179\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred_train))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a5269",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=100,\n",
    "                                random_state=123,\n",
    "                                max_depth = 50)\n",
    "forest.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6402cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8498780258960406\n",
      "Accuracy: 0.7211033274956217\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = forest.predict(test_x)\n",
    "y_pred_train = forest.predict(train_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred_train))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d501c",
   "metadata": {},
   "source": [
    "### Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_boost = CatBoostClassifier(verbose=0, random_state = 123)\n",
    "cat_boost.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2befa205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8478138487521111\n",
      "Accuracy: 0.7390542907180385\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = cat_boost.predict(test_x)\n",
    "y_pred_train = cat_boost.predict(train_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred_train))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4da40",
   "metadata": {},
   "source": [
    "### XGBoost  (Took a long time to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7fba430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=123, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=123, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=123, ...)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg_classifier1 = XGBClassifier(random_state = 123)\n",
    "xg_classifier1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "45642f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8472508913492213\n",
      "Accuracy: 0.7092819614711033\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = xg_classifier1.predict(test_x)\n",
    "y_pred_train = xg_classifier1.predict(train_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_y, y_pred_train))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9851188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
